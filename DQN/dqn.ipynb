{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "import pygame\n",
    "pygame.display.set_mode((600,400))\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v1').unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Linear 입력의 연결 숫자는 conv2d 계층의 출력과 입력 이미지의 크기에\n",
    "        # 따라 결정되기 때문에 따로 계산을 해야합니다.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # gym이 요청한 화면은 400x600x3 이지만, 가끔 800x1200x3 처럼 큰 경우가 있습니다.\n",
    "    # 이것을 Torch order (CHW)로 변환한다.\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # 카트는 아래쪽에 있으므로 화면의 상단과 하단을 제거하십시오.\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # 카트를 중심으로 정사각형 이미지가 되도록 가장자리를 제거하십시오.\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # float 으로 변환하고,  rescale 하고, torch tensor 로 변환하십시오.\n",
    "    # (이것은 복사를 필요로하지 않습니다)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # 크기를 수정하고 배치 차원(BCHW)을 추가하십시오.\n",
    "    return resize(screen).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# AI gym에서 반환된 형태를 기반으로 계층을 초기화 하도록 화면의 크기를\n",
    "# 가져옵니다. 이 시점에 일반적으로 3x40x90 에 가깝습니다.\n",
    "# 이 크기는 get_screen()에서 고정, 축소된 렌더 버퍼의 결과입니다.\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "            # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "            # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "    # 전환합니다.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "    # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
    "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # 기대 Q 값 계산\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Huber 손실 계산\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # 모델 최적화\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Requested MovieWriter (ffmpeg) not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/DQN/dqn2013.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.164.224/opt/ml/DQN/dqn2013.ipynb#ch0000015vscode-remote?line=42'>43</a>\u001b[0m         target_net\u001b[39m.\u001b[39mload_state_dict(policy_net\u001b[39m.\u001b[39mstate_dict())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.164.224/opt/ml/DQN/dqn2013.ipynb#ch0000015vscode-remote?line=43'>44</a>\u001b[0m ani \u001b[39m=\u001b[39m animation\u001b[39m.\u001b[39mArtistAnimation(fig, ims, interval\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B49.50.164.224/opt/ml/DQN/dqn2013.ipynb#ch0000015vscode-remote?line=44'>45</a>\u001b[0m writer \u001b[39m=\u001b[39m animation\u001b[39m.\u001b[39;49mwriters[\u001b[39m'\u001b[39;49m\u001b[39mffmpeg\u001b[39;49m\u001b[39m'\u001b[39;49m](fps\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.164.224/opt/ml/DQN/dqn2013.ipynb#ch0000015vscode-remote?line=45'>46</a>\u001b[0m ani\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_animation.mp4\u001b[39m\u001b[39m\"\u001b[39m, writer\u001b[39m=\u001b[39mwriter, dpi\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.164.224/opt/ml/DQN/dqn2013.ipynb#ch0000015vscode-remote?line=46'>47</a>\u001b[0m \u001b[39m# ani.save('test.mp4', writer='imagemagick')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/animation.py:151\u001b[0m, in \u001b[0;36mMovieWriterRegistry.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/matplotlib/animation.py?line=148'>149</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_available(name):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/matplotlib/animation.py?line=149'>150</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registered[name]\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/matplotlib/animation.py?line=150'>151</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequested MovieWriter (\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m) not available\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requested MovieWriter (ffmpeg) not available"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import animation,rc\n",
    "num_episodes = 50\n",
    "fig,ax = plt.subplots()\n",
    "ims = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    im = ax.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none', animated=True)\n",
    "    ims.append([im])\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # 행동 선택과 수행\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # 새로운 상태 관찰\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # (정책 네트워크에서) 최적화 한단계 수행\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # 목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=100)\n",
    "writer = animation.writers['ffmpeg'](fps=25)\n",
    "ani.save(f\"test_animation.mp4\", writer=writer, dpi=128)\n",
    "# ani.save('test.mp4', writer='imagemagick')\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python ('fastapi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
